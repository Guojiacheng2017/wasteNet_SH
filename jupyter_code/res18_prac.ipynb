{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created by Jiacheng Guo at Dec 4 15:22:58 CST 2021\n",
    "# ResNet --jupyter version\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride = 1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel,outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            #shortcut, make sure the input and output size is matched\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        body = self.block(X)\n",
    "#         print(body.shape, self.shortcut(X).shape)\n",
    "        body = body + self.shortcut(X)\n",
    "        body = F.relu(body)\n",
    "        return body\n",
    "        \n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, num_classes=4):\n",
    "        super(ResNet, self).__init__()\n",
    "        # img.shape = 1 here\n",
    "        self.inchannel = 32\n",
    "        \n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResBlock, 32, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResBlock, 64, 2, stride=2)    # 16\n",
    "        self.layer3 = self.make_layer(ResBlock, 128, 2, stride=2)   # 8\n",
    "        self.layer4 = self.make_layer(ResBlock, 256, 2, stride=2)   # 4\n",
    "        self.avgPool = nn.AvgPool2d(4)  # 1\n",
    "        self.fc = nn.Linear(256, num_classes)   # 1 * 1 * 256\n",
    "        \n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.inchannel, channels, stride))\n",
    "            self.inchannel = channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = self.conv(X)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgPool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    ## used to read binary files since our data files are in binary format\n",
    "    import pickle\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def get_correct_and_accuracy(y_pred, y):\n",
    "    # y_pred is the nxC prediction scores\n",
    "    # give the number of correct and the accuracy\n",
    "    n = y.shape[0]\n",
    "    # find the prediction class label\n",
    "    _ ,pred_class = y_pred.max(dim=1)\n",
    "    correct = (pred_class == y).sum().item()\n",
    "    return correct ,correct/n\n",
    "\n",
    "## loading data from binary data files\n",
    "batch_1_dictionary = unpickle('cifar-10-data/data_batch_1')\n",
    "batch_2_dictionary = unpickle('cifar-10-data/data_batch_2')\n",
    "\n",
    "## get training, validation and testing sets\n",
    "X_train_all = np.array(batch_1_dictionary[b'data']).reshape(10000,3,32,32)  # 3072 = 3 channels x 32 width x 32 length\n",
    "y_train_all = np.array(batch_1_dictionary[b'labels'])\n",
    "validation_count = 1000\n",
    "train_count = X_train_all.shape[0] - validation_count  # 9000\n",
    "# print(\"y_train_all: \", y_train_all)\n",
    "X_train = X_train_all[:train_count] # head 9000\n",
    "y_train = y_train_all[:train_count]\n",
    "X_val = X_train_all[train_count:]  # tail 1000\n",
    "y_val = y_train_all[train_count:]\n",
    "X_test = np.array(batch_2_dictionary[b'data']).reshape(10000,3,32,32) # convert test set into secondary matrix\n",
    "y_test = np.array(batch_2_dictionary[b'labels'])\n",
    "\n",
    "\n",
    "# for RGB data we can simply divide by 255\n",
    "X_train_normalized = X_train / 255\n",
    "X_val_normalized = X_val / 255\n",
    "X_test_normalized = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model structure: ResNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (avgPool): AvgPool2d(kernel_size=4, stride=4, padding=0)\n",
      "  (fc): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "X train tensor shape: torch.Size([9000, 3, 32, 32])\n",
      "n_batch:  282\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "n_iteration = 20\n",
    "batch_size = 32\n",
    "lr = 0.01\n",
    "\n",
    "resNet = ResNet(ResBlock, num_classes=10)\n",
    "print(\"model structure:\", resNet)\n",
    "#\n",
    "optimizer = optim.Adam(resNet.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_data = X_train_normalized.shape[0]\n",
    "n_batch = int(np.ceil(n_data/batch_size))\n",
    "\n",
    "# convert X_train and X_val to tensor\n",
    "X_train_tensor = torch.tensor(X_train_normalized, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val_normalized, dtype=torch.float32)\n",
    "\n",
    "# convert training label to tensor and to type long\n",
    "y_train_tensor = torch.tensor(y_train).long()\n",
    "y_val_tensor = torch.tensor(y_val).long()\n",
    "\n",
    "print('X train tensor shape:', X_train_tensor.shape)\n",
    "print('n_batch: ', n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 ,Train loss: 1.732, Train acc: 0.375, Val loss: 1.541, Val acc: 0.445\n",
      "iteration 0 :\t 137.5869221687317\n",
      "Iter 1 ,Train loss: 1.415, Train acc: 0.625, Val loss: 1.308, Val acc: 0.527\n",
      "iteration 1 :\t 133.7649598121643\n",
      "Iter 2 ,Train loss: 1.188, Train acc: 0.750, Val loss: 1.135, Val acc: 0.597\n",
      "iteration 2 :\t 134.0323669910431\n",
      "Iter 3 ,Train loss: 1.004, Train acc: 0.875, Val loss: 1.068, Val acc: 0.613\n",
      "iteration 3 :\t 134.31848692893982\n",
      "Iter 4 ,Train loss: 0.834, Train acc: 1.000, Val loss: 1.175, Val acc: 0.617\n",
      "iteration 4 :\t 133.27251815795898\n",
      "Iter 5 ,Train loss: 0.673, Train acc: 1.000, Val loss: 1.214, Val acc: 0.609\n",
      "iteration 5 :\t 132.8900010585785\n",
      "Iter 6 ,Train loss: 0.511, Train acc: 1.000, Val loss: 1.422, Val acc: 0.604\n",
      "iteration 6 :\t 134.5874948501587\n",
      "Iter 7 ,Train loss: 0.379, Train acc: 1.000, Val loss: 1.532, Val acc: 0.595\n",
      "iteration 7 :\t 136.06651496887207\n",
      "Iter 8 ,Train loss: 0.269, Train acc: 1.000, Val loss: 1.564, Val acc: 0.621\n",
      "iteration 8 :\t 128.38378763198853\n",
      "Iter 9 ,Train loss: 0.174, Train acc: 1.000, Val loss: 1.607, Val acc: 0.633\n",
      "iteration 9 :\t 129.02656483650208\n",
      "Iter 10 ,Train loss: 0.122, Train acc: 1.000, Val loss: 1.617, Val acc: 0.649\n",
      "iteration 10 :\t 129.54902482032776\n",
      "Iter 11 ,Train loss: 0.101, Train acc: 0.875, Val loss: 1.654, Val acc: 0.650\n",
      "iteration 11 :\t 128.658038854599\n",
      "Iter 12 ,Train loss: 0.087, Train acc: 1.000, Val loss: 1.686, Val acc: 0.653\n",
      "iteration 12 :\t 133.43986892700195\n",
      "Iter 13 ,Train loss: 0.070, Train acc: 1.000, Val loss: 1.704, Val acc: 0.656\n",
      "iteration 13 :\t 131.34662699699402\n",
      "Iter 14 ,Train loss: 0.051, Train acc: 1.000, Val loss: 1.795, Val acc: 0.656\n",
      "iteration 14 :\t 137.67269802093506\n",
      "Iter 15 ,Train loss: 0.052, Train acc: 1.000, Val loss: 1.853, Val acc: 0.654\n",
      "iteration 15 :\t 138.51020503044128\n",
      "Iter 16 ,Train loss: 0.072, Train acc: 1.000, Val loss: 1.696, Val acc: 0.673\n",
      "iteration 16 :\t 135.19651007652283\n",
      "Iter 17 ,Train loss: 0.067, Train acc: 1.000, Val loss: 1.775, Val acc: 0.657\n",
      "iteration 17 :\t 136.388414144516\n",
      "Iter 18 ,Train loss: 0.061, Train acc: 1.000, Val loss: 2.007, Val acc: 0.642\n",
      "iteration 18 :\t 140.2042179107666\n",
      "Iter 19 ,Train loss: 0.062, Train acc: 1.000, Val loss: 1.927, Val acc: 0.672\n",
      "iteration 19 :\t 129.14734816551208\n"
     ]
    }
   ],
   "source": [
    "## start \n",
    "train_loss_list = np.zeros(n_iteration)\n",
    "train_accu_list = np.zeros(n_iteration)\n",
    "val_loss_list = np.zeros(n_iteration)\n",
    "val_accu_list = np.zeros(n_iteration)\n",
    "\n",
    "import time\n",
    "\n",
    "for i in range(n_iteration):\n",
    "    # first get a minibatch of data\n",
    "    train_loss = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for j in range(n_batch):\n",
    "#         print(\"\\nbatch\", j, \":\")\n",
    "#         start_time = time.time()\n",
    "        \n",
    "        batch_start_index = j*batch_size\n",
    "        # get data batch from the normalized data\n",
    "        X_batch = X_train_tensor[batch_start_index:batch_start_index+batch_size]\n",
    "        # get ground truth label y\n",
    "        y_batch = y_train_tensor[batch_start_index:batch_start_index+batch_size]\n",
    "\n",
    "#         print(X_batch.shape)\n",
    "        train_pred = resNet(X_batch)\n",
    "#         print(train_pred.shape)\n",
    "        train_crt, train_accu = get_correct_and_accuracy(train_pred, y_batch)\n",
    "        train_loss_i = criterion(train_pred, y_batch)\n",
    "        \n",
    "#         train_loss.append(train_loss_i)\n",
    "        train_loss.append(train_loss_i.detach().numpy())\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        train_loss_i.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "#         print(\"batch\", j, \":\\t\", time.time() - start_time)\n",
    "\n",
    "    # \n",
    "    val_pred = resNet(X_val_tensor)\n",
    "    val_crt, val_accu = get_correct_and_accuracy(val_pred, y_val_tensor)\n",
    "    val_loss = criterion(val_pred, y_val_tensor)\n",
    "    \n",
    "    ave_train_loss = np.sum(train_loss)/len(train_loss)\n",
    "        \n",
    "    print(\"Iter %d ,Train loss: %.3f, Train acc: %.3f, Val loss: %.3f, Val acc: %.3f\" \n",
    "          %(i ,ave_train_loss, train_accu, val_loss, val_accu)) \n",
    "    ## add to the logs so that we can use them later for plotting\n",
    "    train_loss_list[i] = ave_train_loss\n",
    "    train_accu_list[i] = train_accu\n",
    "    val_loss_list[i] = val_loss\n",
    "    val_accu_list[i] = val_accu\n",
    "    print(\"iteration\", i, \":\\t\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# a = [0, 0, 1, 0]\n",
    "# print(a.index(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
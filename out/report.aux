\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {paragraph}{In Shanghai, garbage classification has been implemented for more than 20 years. Meanwhile, the classification standard has changed many times. Published on July 1, 2019, Shanghai Municipal Household Garbage Management Regulations divides the classification standard into four categories: recyclable waste, residual waste, household waste and hazardous waste. The strict implementation with high quality of garbage classification cannot be separated from the accurate classification by every citizen in Shanghai. In this project, we want to develop a framework to automatic garbage categorization.}{1}{figure.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Similar to how people identify garbage categories, we also want our framework to be able to output garbage categories when it sees the garbage (i.e., the input image). The first step in this process requires the ability to recognize the content of the input image. In the field of image identification, machine learning, especially convolutional neural networks, has huge advantages. After recognizing the image content, our method needs to classify it. Also, there are many classification algorithms in machine learning, with which we hope to achieve good classification performance.}{1}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{We have noticed that many papers have made outstanding contributions in the field of image identification, such as gradient-based Learning Applied to Document Recognition, Very Deep Convolutional Networks for large-scale Image Recognition. We will draw on established algorithms to develop this framework for our project.}{1}{section*.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Standard for waste classification from CGTN}}{2}{figure.1}\protected@file@percent }
\newlabel{fig:Trash_classification}{{1}{2}{Standard for waste classification from CGTN}{figure.1}{}}
\@writefile{toc}{\contentsline {paragraph}{}{3}{section*.8}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Neural network has already taken a place for many years. Based on the practical experience and experiment result, it performed pretty well, even better than the traditional machine learning algorithm. And the convolutional neural network is one of the main categories to do computer vision tasks both in recognition and classification. Since the project is based on the image classification, the most common way to classify the image for now is to use deep neural network. And this is also the most mature way in computer vision, so we here specify three different network for training.}{3}{section*.10}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The basic CNN with 2 convolution layers and 3 fully connected layers that for trash classification tasks is as the base line for the improvement of other models. And compare with the basic CNN, wasteCNN add one convolutional layer addition for improvement; and another neural network is Res18, cascading with previous layers. This kind of skip connection let the ResNet able to preserve the feature from previous layers, make the network much easier to preserve the gradient.}{3}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{And as for the model chosen process, because if the model is much deeper, then the time consuming for training process will be much longer, so the res18 is the deepest network we choose. It is true that the Res50 will have much deeper network and similar amount of parameter for the network (or in other work the size of the network), it is also the network we want to realize by ourselves, but these are sufficient to classify the trash by these models and choose the best one. }{3}{section*.13}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Convolutional Neural Network structure}}{4}{figure.2}\protected@file@percent }
\newlabel{fig:cnn_model}{{2}{4}{Convolutional Neural Network structure}{figure.2}{}}
\@writefile{toc}{\contentsline {paragraph}{Figure \ref  {fig:cnn_model} show the model structure with the image size is 128, adjusting the image size will affect the model’s first fully connected layer.}{4}{figure.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{The model structure is shown in Figure \ref  {fig:wasteNet_model} with the image size is 128, adjusting the image size will affect the model’s first fully connected layer. Basic backbone is as same as CNN. The difference is that there is 3 convolutional layers and larger fully connected layer.}{4}{figure.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces wasteCNN model structure}}{5}{figure.3}\protected@file@percent }
\newlabel{fig:wasteNet_model}{{3}{5}{wasteCNN model structure}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Part of ResNet with 18 convolutional layer}}{6}{figure.4}\protected@file@percent }
\newlabel{fig:res18_model}{{4}{6}{Part of ResNet with 18 convolutional layer}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Accuracy-Epoch Curve}}{7}{figure.5}\protected@file@percent }
\newlabel{fig:Accuracy}{{5}{7}{Accuracy-Epoch Curve}{figure.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Res18 has 18 convolutional layers. First thing is to construct the ResBlock, which is the basic component for the ResNet. ResBlock is built by two convolutional layers and a shortcut, which represent the combination of current Conv layer output and previous output. Then connect with 4 blocks and addition 1 conv-layer in the front and 1 fully connected layer at the end. And the part of ResNet is also shown as Figure \ref  {fig:res18_model}}{7}{figure.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces AUC value-Epoch Curve}}{8}{figure.6}\protected@file@percent }
\newlabel{fig:AUC}{{6}{8}{AUC value-Epoch Curve}{figure.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Confusion metrics and ROC curves of CNN}}{9}{figure.7}\protected@file@percent }
\newlabel{fig:CNN_confusion_ROC}{{7}{9}{Confusion metrics and ROC curves of CNN}{figure.7}{}}
\@writefile{toc}{\contentsline {paragraph}{The project separately evaluates these three kinds of models by using many evaluation methods and obtained the following figures and results: the variation curve of Test Accuracy with the number of epochs shown as Figure \ref  {fig:Accuracy}. And the variation curve of AUC value with the number of epochs as Figure \ref  {fig:AUC}.}{9}{figure.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{According to figures 6 and 7, the project selects the iteration that performs better in the test dataset and get the confusion matrix and ROC curve (after averaging the four categories) under that iteration. Then calculate the Precision, Recall for each category.}{9}{section*.22}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Due to the uneven distribution of data in the test set, the project decides to calculate the macro average and micro average of precision, recall and F1-score of the three models respectively to compare the performance.}{9}{table.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Confusion metrics and ROC curves of WasteCNN}}{10}{figure.8}\protected@file@percent }
\newlabel{fig:WasteCNN_confusion_ROC}{{8}{10}{Confusion metrics and ROC curves of WasteCNN}{figure.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Value of precision, recall and F1-score}}{10}{table.1}\protected@file@percent }
\newlabel{tab:my_label}{{1}{10}{Value of precision, recall and F1-score}{table.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Confusion metrics and ROC curves of Res18}}{11}{figure.9}\protected@file@percent }
\newlabel{fig:Res18_confusion_ROC}{{9}{11}{Confusion metrics and ROC curves of Res18}{figure.9}{}}
\citation{*}
\bibstyle{IEEEtran}
\bibdata{references}
\@writefile{toc}{\contentsline {paragraph}{These results shows that Res18 model has the highest accuracy when predicting the test dataset, accuracy is up to 89\% within 50 iterations, while the accuracy of CNN and wasteCNN models is about 83\% and 85\%. In addition, the average Precision, Recall and F1-score values of the Res18 model are also the closest to "1". The Precision, Recall and F1-score calculated by macro and micro average methods are basically the same, indicating the accuracy of classification is not affected by the number of samples in different categories. The AUC value of Res18 model is up to 0.97 within 50 iterations, which is also higher than in the wasteCNN and CNN models. Hence, it can be seen that Res18 model is the most accurate in the classification of trash pictures among these three models.}{12}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{However, in the case of calculating the values of precision and recall by category of garbage, the classification accuracy of the three models is the highest for recyclable trash, which is up to 96\%, but lower for dry trash and poison trash categories. This problem needs further study.}{12}{section*.25}\protected@file@percent }
